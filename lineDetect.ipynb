{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lineDetect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOWv2x7dKhF95D0MBZ9R9cS"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH6JhRJhswLy",
        "outputId": "f435dabb-1edf-4665-e67f-4c57dda96487"
      },
      "source": [
        "!npm install jupnode\n",
        "import jupnode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "> jupnode@0.5.73 install /content/node_modules/jupnode\n",
            "> node ./install\n",
            "\n",
            "Processing ./jupnode-0.0.0.tar.gz\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from jupnode==0.0.0) (0.36.2)\n",
            "Building wheels for collected packages: jupnode\n",
            "  Building wheel for jupnode (setup.py): started\n",
            "  Building wheel for jupnode (setup.py): finished with status 'done'\n",
            "  Created wheel for jupnode: filename=jupnode-0.0.0-cp37-none-any.whl size=267839 sha256=083fc7e415d2a66eb19c6f3e98da59affb816012b6ec159883e6a386b58927ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/2b/76/03debf4dac1dd365dc0362fe7beca25a42fa452d4a3bf8e9ef\n",
            "Successfully built jupnode\n",
            "Installing collected packages: jupnode\n",
            "Successfully installed jupnode-0.0.0\n",
            "\n",
            "\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ jupnode@0.5.73\n",
            "added 1 package from 1 contributor and audited 1 package in 4.385s\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3_GMsLttrTU",
        "outputId": "38f0252d-252c-4b24-f0a3-2720bfd09447"
      },
      "source": [
        "sh('git clone https://github.com/Graphnull/enheg');\n",
        "sh('npm i sharp');\n",
        "sh(`npm i @tensorflow/tfjs-node-gpu`);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'enheg'...\n",
            "> sharp@0.28.3 install /content/node_modules/sharp\n",
            "> (node install/libvips && node install/dll-copy && prebuild-install) || (node install/can-compile && node-gyp rebuild && node install/dll-copy)\n",
            "sharp: Downloading https://github.com/lovell/sharp-libvips/releases/download/v8.10.6/libvips-8.10.6-linux-x64.tar.br\n",
            "npm WARN saveError ENOENT: no such file or directory, open '/content/package.json'\n",
            "npm WARN enoent ENOENT: no such file or directory, open '/content/package.json'\n",
            "npm WARN content No description\n",
            "npm WARN content No repository field.\n",
            "npm WARN content No README data\n",
            "npm WARN content No license field.\n",
            "+ sharp@0.28.3\n",
            "added 68 packages from 192 contributors and audited 69 packages in 4.504s\n",
            "6 packages are looking for funding\n",
            "run `npm fund` for details\n",
            "found 0 vulnerabilities\n",
            "> @tensorflow/tfjs-node-gpu@3.7.0 install /content/node_modules/@tensorflow/tfjs-node-gpu\n",
            "> node scripts/install.js gpu download\n",
            "GPU-linux-3.7.0.tar.gz\n",
            "* Downloading libtensorflow\n",
            "* Building TensorFlow Node.js bindings\n",
            "> core-js@3.14.0 postinstall /content/node_modules/core-js\n",
            "> node -e \"try{require('./postinstall')}catch(e){}\"\n",
            "\u001b[96mThank you for using core-js (\u001b[94m https://github.com/zloirock/core-js \u001b[96m) for polyfilling JavaScript standard library!\u001b[0m\n",
            "\u001b[96mThe project needs your help! Please consider supporting of core-js on Open Collective or Patreon: \u001b[0m\n",
            "\u001b[96m>\u001b[94m https://opencollective.com/core-js \u001b[0m\n",
            "\u001b[96m>\u001b[94m https://www.patreon.com/zloirock \u001b[0m\n",
            "\u001b[96mAlso, the author of core-js (\u001b[94m https://github.com/zloirock \u001b[96m) is looking for a good job -)\u001b[0m\n",
            "npm WARN saveError ENOENT: no such file or directory, open '/content/package.json'\n",
            "npm WARN enoent ENOENT: no such file or directory, open '/content/package.json'\n",
            "npm WARN content No description\n",
            "npm WARN content No repository field.\n",
            "npm WARN content No README data\n",
            "npm WARN content No license field.\n",
            "+ @tensorflow/tfjs-node-gpu@3.7.0\n",
            "added 94 packages from 97 contributors and audited 200 packages in 15.901s\n",
            "13 packages are looking for funding\n",
            "run `npm fund` for details\n",
            "found 0 vulnerabilities\n",
            "{\n",
            "status: 0,\n",
            "signal: null,\n",
            "output: [ null, null, null ],\n",
            "pid: 245,\n",
            "stdout: null,\n",
            "stderr: null\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT2Z9AQ32jnx",
        "outputId": "4112398a-fe95-4b3b-947c-ec7f085123bc"
      },
      "source": [
        "let tf = require('@tensorflow/tfjs-node-gpu')\n",
        "\n",
        "\n",
        "let model = null;\n",
        "//try{\n",
        "//  model = await tf.loadLayersModel('file://./model/model.json');\n",
        "//}catch(err){\n",
        "  //  console.log(err)\n",
        "  model = tf.sequential();\n",
        "  model.add(tf.layers.conv2d({ filters: 128, kernelSize: [9, 9], activation: 'linear', padding: 'same', useBias: true, inputShape: [null,null, 1]}));\n",
        "  model.add(tf.layers.leakyReLU());\n",
        "  model.add(tf.layers.conv2d({ filters: 64, kernelSize: [5, 5], activation: 'linear', padding: 'same', useBias: true }));\n",
        "  model.add(tf.layers.leakyReLU());\n",
        "  model.add(tf.layers.conv2d({ filters: 32, kernelSize: [3, 3], activation: 'linear', padding: 'same', useBias: true }));\n",
        "  model.add(tf.layers.leakyReLU());\n",
        "  model.add(tf.layers.conv2d({ filters: 32, kernelSize: [3, 3], activation: 'linear', padding: 'same', useBias: true }));\n",
        "  model.add(tf.layers.activation({activation: 'relu6'}));\n",
        "  model.add(tf.layers.conv2d({ filters: 1, kernelSize: [3, 3], activation: 'linear', padding: 'same', useBias: true }));\n",
        "  model.add(tf.layers.leakyReLU());\n",
        "//}\n",
        "model.summary();\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output shape              Param #\n",
            "=================================================================\n",
            "conv2d_Conv2D16 (Conv2D)     [null,null,null,128]      10496\n",
            "_________________________________________________________________\n",
            "leaky_re_lu_LeakyReLU16 (Lea [null,null,null,128]      0\n",
            "_________________________________________________________________\n",
            "conv2d_Conv2D17 (Conv2D)     [null,null,null,64]       204864\n",
            "_________________________________________________________________\n",
            "leaky_re_lu_LeakyReLU17 (Lea [null,null,null,64]       0\n",
            "_________________________________________________________________\n",
            "conv2d_Conv2D18 (Conv2D)     [null,null,null,32]       18464\n",
            "_________________________________________________________________\n",
            "leaky_re_lu_LeakyReLU18 (Lea [null,null,null,32]       0\n",
            "_________________________________________________________________\n",
            "conv2d_Conv2D19 (Conv2D)     [null,null,null,32]       9248\n",
            "_________________________________________________________________\n",
            "activation_Activation1 (Acti [null,null,null,32]       0\n",
            "_________________________________________________________________\n",
            "conv2d_Conv2D20 (Conv2D)     [null,null,null,1]        289\n",
            "_________________________________________________________________\n",
            "leaky_re_lu_LeakyReLU19 (Lea [null,null,null,1]        0\n",
            "=================================================================\n",
            "Total params: 243361\n",
            "Trainable params: 243361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO5tJfiit6zN",
        "outputId": "b15e454e-bc32-4c5a-d349-a18fbe28114b"
      },
      "source": [
        "let generateDataset = require('./enheg/dataset_generate/index')\n",
        "\n",
        "let loss = (result, output) => {\n",
        "    let start = [0, 16, 16, 0];\n",
        "    let end = [result.shape[0], result.shape[1]-32, result.shape[2]-32, 1];\n",
        "  return tf.pow(result.sub(output), 2)\n",
        "  .slice(start, end)\n",
        "  .mean();\n",
        "}\n",
        "\n",
        "model.compile({loss, optimizer: tf.train.adam(0.00001)});\n",
        "\n",
        "for(let i=0;i!==100;i++){\n",
        "    \n",
        "    let { result, lines, width, height} = await generateDataset()\n",
        "    let [x, y] = tf.tidy(()=>{\n",
        "        let x = tf.tensor(result,[1,height/2, width/2,1]).div(255)\n",
        "        let y = tf.tensor(lines,[1,height/2, width/2,1]).div(255)\n",
        "      return [x, y]\n",
        "    })\n",
        "    \n",
        "    let loss = await model.trainOnBatch (x, y)\n",
        "    console.log(loss);\n",
        "    x.dispose()\n",
        "    y.dispose()\n",
        "    \n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.005379193462431431\n",
            "\n",
            "0.01062831375747919\n",
            "\n",
            "0.0067602964118123055\n",
            "\n",
            "0.006160244345664978\n",
            "\n",
            "0.004389761947095394\n",
            "\n",
            "0.004602991044521332\n",
            "\n",
            "0.005296221934258938\n",
            "\n",
            "0.006149146240204573\n",
            "\n",
            "0.005243709776550531\n",
            "\n",
            "0.004129026085138321\n",
            "\n",
            "0.004705223720520735\n",
            "\n",
            "0.010909659788012505\n",
            "\n",
            "0.004940909333527088\n",
            "\n",
            "0.006218838971108198\n",
            "\n",
            "0.006531533785164356\n",
            "\n",
            "0.004851779900491238\n",
            "\n",
            "0.007370542269200087\n",
            "\n",
            "0.011510654352605343\n",
            "\n",
            "0.00869839359074831\n",
            "\n",
            "0.004597460851073265\n",
            "\n",
            "0.005532768554985523\n",
            "\n",
            "0.004371343180537224\n",
            "\n",
            "0.005166751332581043\n",
            "\n",
            "0.005593631416559219\n",
            "\n",
            "0.007957161404192448\n",
            "\n",
            "0.006552577018737793\n",
            "\n",
            "0.004700528457760811\n",
            "\n",
            "0.0049538505263626575\n",
            "\n",
            "0.004767747595906258\n",
            "\n",
            "0.004547858610749245\n",
            "\n",
            "0.008279027417302132\n",
            "\n",
            "0.00807182863354683\n",
            "\n",
            "0.004808067809790373\n",
            "\n",
            "0.004947110544890165\n",
            "\n",
            "0.004383542574942112\n",
            "\n",
            "0.004720297642052174\n",
            "\n",
            "0.006626555696129799\n",
            "\n",
            "0.004821358248591423\n",
            "\n",
            "0.004252876620739698\n",
            "\n",
            "0.005432016681879759\n",
            "\n",
            "0.004664058331400156\n",
            "\n",
            "0.010449804365634918\n",
            "\n",
            "0.005473668687045574\n",
            "\n",
            "0.004283275455236435\n",
            "\n",
            "0.00756117282435298\n",
            "\n",
            "0.004941340535879135\n",
            "\n",
            "0.005903600715100765\n",
            "\n",
            "0.00518105598166585\n",
            "\n",
            "0.004167928826063871\n",
            "\n",
            "0.005480681546032429\n",
            "\n",
            "0.005018375813961029\n",
            "\n",
            "0.005681940354406834\n",
            "\n",
            "0.0064096045680344105\n",
            "\n",
            "0.004319056868553162\n",
            "\n",
            "0.007207503076642752\n",
            "\n",
            "0.006459804251790047\n",
            "\n",
            "0.004502385389059782\n",
            "\n",
            "0.00622689351439476\n",
            "\n",
            "0.0058443560265004635\n",
            "\n",
            "0.0039055293891578913\n",
            "\n",
            "0.005911078304052353\n",
            "\n",
            "0.007333279121667147\n",
            "\n",
            "0.004245598800480366\n",
            "\n",
            "0.004863407928496599\n",
            "\n",
            "0.0051794275641441345\n",
            "\n",
            "0.004080977290868759\n",
            "\n",
            "0.004566333256661892\n",
            "\n",
            "0.004486467689275742\n",
            "\n",
            "0.005848770495504141\n",
            "\n",
            "0.006229966878890991\n",
            "\n",
            "0.005098260473459959\n",
            "\n",
            "0.0045160758309066296\n",
            "\n",
            "0.004782385658472776\n",
            "\n",
            "0.004576856270432472\n",
            "\n",
            "0.0068533821031451225\n",
            "\n",
            "0.00883207656443119\n",
            "\n",
            "0.004651895258575678\n",
            "\n",
            "0.006068515125662088\n",
            "\n",
            "0.004301874898374081\n",
            "\n",
            "0.0072308313101530075\n",
            "\n",
            "0.004566994030028582\n",
            "\n",
            "0.005118477623909712\n",
            "\n",
            "0.005455033387988806\n",
            "\n",
            "0.005230668932199478\n",
            "\n",
            "0.0047165085561573505\n",
            "\n",
            "0.004441604018211365\n",
            "\n",
            "0.00613793870434165\n",
            "\n",
            "0.006508100312203169\n",
            "\n",
            "0.005808657500892878\n",
            "\n",
            "0.005752153228968382\n",
            "\n",
            "0.00478643923997879\n",
            "\n",
            "0.007195676676928997\n",
            "\n",
            "0.007291012909263372\n",
            "\n",
            "0.005522648338228464\n",
            "\n",
            "0.0050521427765488625\n",
            "\n",
            "0.00427992781624198\n",
            "\n",
            "0.00458771176636219\n",
            "\n",
            "0.004396733827888966\n",
            "\n",
            "0.004371972754597664\n",
            "\n",
            "0.003979519009590149\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRokSXYDJDJS"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRNKbVDu70T3",
        "outputId": "51572ddd-a022-4184-9a4b-daa03ab380f9"
      },
      "source": [
        "await model.save('file://model');"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "modelArtifactsInfo: {\n",
            "dateSaved: 2021-06-17T08:16:40.865Z,\n",
            "modelTopologyType: 'JSON',\n",
            "modelTopologyBytes: 3405,\n",
            "weightSpecsBytes: 676,\n",
            "weightDataBytes: 973444\n",
            "}\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}